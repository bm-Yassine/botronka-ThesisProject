- Hostname :
botronka
- password:
ybpi
- Raspberry pi ssh public key
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIME6+EM5L+4bRR3xJtkwhyAp21GUrPzYVY8dEGcCLPQB raspberrypi

- access ssh
ssh botronka@botronka.local
ssh botronka@192.168.2.30



1) Basic interactions to implement now (v0)
- Inputs
Camera: face detected / not detected, 
Ultrasonic: distance in front
Internal health: exceptions, timeouts, low FPS, sensor failures
Mic : face detected

- Core states (emotions)
GREETING → face appears after being absent 
HAPPY → everything normal (no obstacle, no error)
SUSPICIOUS → face detected but unknown 
LONELY → no face detected for X seconds
STUCK → obstacle too close for > X seconds (or later: all directions blocked)
ANGRY → error in a module (camera fail, OLED fail, sensor fail)
CURIOUS → object/face detected but confidence low
SLEEPY → idle too long
ALERT → distance suddenly drops (someone approaches fast)

- Buzzer notification events
STUCK (short triple beep)
ERROR (long + long)
NEW_FACE (single chirp)
TOO_CLOSE (fast beeps)
LOW_BATTERY, WAKE_WORD, TRUST_DENIED, TRUST_GRANTED

- Audio states
IDLE: no face → mic off
ENGAGED: face detected (and optionally recognized) → mic on
LISTENING: record until end-of-speech (VAD)
THINKING: STT → NLU/Agent decision
SPEAKING / ACTING: TTS + execute safe commands
back to ENGAGED until 4s after face disappears or timeout